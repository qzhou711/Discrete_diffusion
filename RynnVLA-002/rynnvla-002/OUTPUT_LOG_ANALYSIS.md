# Output.log 日志文件分析说明

`output.log` 文件包含了训练过程的完整输出日志，记录了从启动到训练结束的所有信息。

## 日志结构概览

日志文件主要包含以下几个部分：

1. **初始化阶段**（文件开头）
2. **训练过程日志**（主要部分）
3. **错误信息**（如果有）
4. **训练结束信息**

---

## 1. 初始化阶段

### 1.1 环境警告信息

```
[WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1
```
- **含义**: PyTorch分布式训练的警告，自动设置OMP线程数
- **作用**: 避免系统过载，每个进程使用1个线程

### 1.2 Apex优化器警告

```
UserWarning: cannot import FusedAdam from apex, use torch AdamW instead
```
- **含义**: 无法导入Apex的FusedAdam优化器，回退使用PyTorch的AdamW
- **影响**: 性能可能略低，但不影响训练功能
- **解决方法**: 安装apex库（可选）

### 1.3 分布式初始化信息

```
distributed init (rank X): env://, gpu Y
```
- **含义**: 分布式训练的初始化信息
- **rank X**: 进程编号（0-4表示5个GPU）
- **gpu Y**: 分配的GPU编号

---

## 2. 训练过程日志格式

训练过程中的日志行格式如下：

```
[rank0:INFO|misc.py:146] 2026-01-05 10:33:33,342 >> Epoch: [12]  [740/2592]  lr: 0.000005  acc_action_5: 0.0000 (0.0000)  l1_loss_action_5: 1.0589 (1.0589)  ...  time: 14.7298  data: 0.0008  samples/sec: 0.68  max mem: 15722
```

### 2.1 日志头部信息

| 字段 | 含义 | 示例 |
|------|------|------|
| `[rank0:INFO\|misc.py:146]` | 日志级别和来源 | rank0表示主进程，INFO表示信息级别 |
| `2026-01-05 10:33:33,342` | 时间戳 | 年-月-日 时:分:秒.毫秒 |

### 2.2 训练进度信息

| 字段 | 含义 | 示例值 |
|------|------|--------|
| `Epoch: [X]` | 当前训练轮次 | `[12]` 表示第12个epoch |
| `[Y/Z]` | 当前batch/总batch数 | `[740/2592]` 表示第740个batch，共2592个 |

### 2.3 超参数和配置

| 字段 | 含义 | 说明 |
|------|------|------|
| `lr: X` | 学习率 (Learning Rate) | 当前使用的学习率，如 `0.000005` (5e-6) |

### 2.4 指标格式说明

每个指标通常显示为：`指标名: 当前值 (平均值)`

- **当前值**: 当前batch/迭代的值
- **平均值**: 从epoch开始到当前的平均值（平滑值）

### 2.5 Loss指标

| 指标 | 全称 | 含义 | 参考文档 |
|------|------|------|----------|
| `closs` | Classification Loss | 分类损失，语言模型的核心损失 | 详见 `LOSS_EXPLANATION.md` |
| `loss_ct` | Continuous Token Loss | 连续动作头的L1损失 | 详见 `LOSS_EXPLANATION.md` |
| `z_loss` | Z Loss | Z损失，用于训练稳定性 | 详见 `LOSS_EXPLANATION.md` |

**示例**: `closs: 8.5075 (8.5075)`
- 当前值: 8.5075
- 平均值: 8.5075（因为只有一个样本，所以相同）

### 2.6 Action相关指标

| 指标 | 含义 | 说明 |
|------|------|------|
| `acc_action_X` | Action准确率（第X个时间步） | 预测action token的准确率，范围0-1 |
| `l1_loss_action_X` | Action L1损失（第X个时间步） | 连续动作空间的L1损失（MAE） |

**示例**: 
- `acc_action_5: 0.0000 (0.0000)` - 第5个时间步的action准确率为0
- `l1_loss_action_5: 1.0589 (1.0589)` - 第5个时间步的L1损失为1.0589

**说明**: 数字（5, 6, 7, 8, 9）表示不同的时间步（time steps）

### 2.7 Image相关指标

| 指标 | 含义 | 说明 |
|------|------|------|
| `acc_image_X` | Image准确率（第X个时间步） | 预测image token的准确率，范围0-1 |

**示例**: `acc_image_8: 0.0000 (0.0000)` - 第8个时间步的image准确率为0

### 2.8 训练状态指标

| 指标 | 含义 | 说明 |
|------|------|------|
| `grad_norm` | Gradient Norm | 梯度范数，用于监控梯度大小 |
| `time` | 迭代时间（秒） | 处理一个batch所需的时间 |
| `data` | 数据加载时间（秒） | 加载数据所需的时间 |
| `samples/sec` | 样本处理速度 | 每秒处理的样本数 |
| `max mem` | 最大显存（MB） | GPU使用的最大显存，单位MB |

**示例**: 
- `grad_norm: 36.8418 (36.8418)` - 梯度范数为36.84
- `time: 14.7298` - 每个batch耗时约14.7秒
- `data: 0.0008` - 数据加载耗时0.0008秒（几乎可以忽略）
- `samples/sec: 0.68` - 每秒处理0.68个样本
- `max mem: 15722` - 最大显存使用约15.7GB

---

## 3. 完整日志行示例解析

```
[rank0:INFO|misc.py:146] 2026-01-05 10:33:33,342 >> Epoch: [12]  [740/2592]  lr: 0.000005  acc_action_5: 0.0000 (0.0000)  l1_loss_action_5: 1.0589 (1.0589)  acc_action_6: 0.0000 (0.0000)  l1_loss_action_6: 1.0599 (1.0599)  acc_action_7: 0.0000 (0.0000)  l1_loss_action_7: 1.0577 (1.0577)  acc_action_8: 0.0000 (0.0000)  l1_loss_action_8: 1.0576 (1.0576)  acc_action_9: 0.0000 (0.0000)  l1_loss_action_9: 1.0245 (1.0245)  closs: 8.5075 (8.5075)  loss_ct: 0.1279 (0.1279)  z_loss: 146.9875 (146.9875)  acc_image_8: 0.0000 (0.0000)  acc_image_9: 0.0000 (0.0000)  grad_norm: 36.8418 (36.8418)  time: 14.7298  data: 0.0008  samples/sec: 0.68  max mem: 15722
```

**解析**:
- **时间**: 2026-01-05 10:33:33
- **Epoch**: 第12轮训练
- **进度**: 740/2592 batches（约28.5%）
- **学习率**: 5e-6
- **主要Loss**: 
  - closs: 8.5075
  - loss_ct: 0.1279
  - z_loss: 146.9875
- **Action指标**: 5个时间步的准确率和L1损失
- **性能**: 每个batch约14.7秒，显存使用15.7GB

---

## 4. 平均统计信息（Epoch结束）

在每个epoch结束时，会输出平均统计信息：

```
Averaged stats:
  lr: 0.000005 (0.000005)
  acc_action_5: 0.0000 (0.0000)
  ...
  closs: 8.5050 (8.5050)
  ...
```

这些是**整个epoch的平均值**，会被写入到 `log_train.txt` 文件中。

---

## 5. 关键指标解读建议

### 5.1 需要关注的指标

1. **closs (Classification Loss)**
   - 应该逐渐下降
   - 如果突然增大，可能是学习率过大或数据问题

2. **loss_ct (Continuous Token Loss)**
   - 应该逐渐下降
   - 反映动作预测能力的提升

3. **l1_loss_action_X**
   - 应该逐渐下降
   - 反映动作预测精度的提升

4. **grad_norm**
   - 应该在合理范围内（通常 < 100）
   - 如果过大，可能存在梯度爆炸
   - 如果过小，可能存在梯度消失

5. **samples/sec**
   - 训练速度指标
   - 可以用来估算剩余训练时间

6. **max mem**
   - 显存使用情况
   - 如果接近GPU显存上限，需要注意OOM风险

### 5.2 指标的正常范围

- **closs**: 通常在 1-10 之间（根据任务不同而变化）
- **loss_ct**: 通常在 0.01-1.0 之间
- **z_loss**: 通常在 30-150 之间（主要用于稳定性，不直接影响性能）
- **l1_loss_action_X**: 通常在 0.1-2.0 之间（越小越好）
- **grad_norm**: 通常在 1-100 之间
- **acc_action_X**: 0-1 之间（越大越好，但某些任务可能较低）

### 5.3 异常情况识别

1. **Loss突然增大（NaN/Inf）**
   - 检查数据、学习率、数值稳定性

2. **Grad_norm过大（>100）**
   - 可能存在梯度爆炸，需要减小学习率或使用梯度裁剪

3. **显存不足（接近GPU上限）**
   - 减小batch_size、序列长度，或使用更多GPU

4. **训练速度过慢**
   - 检查数据加载效率（data时间）、GPU利用率

---

## 6. 日志文件位置

- **实时日志**: `output.log` - 所有进程的输出（通过 `tee` 合并）
- **主进程日志**: `rank-0.log` - 仅rank 0进程的日志
- **训练指标**: `log_train.txt` - epoch级别的平均指标（JSON格式）
- **TensorBoard日志**: `tensorboard/` - 用于可视化

---

## 7. 使用建议

1. **监控训练进度**: 使用 `tail -f output.log` 实时查看训练日志
2. **分析指标趋势**: 使用提供的 `plot_loss_curves.py` 脚本绘制loss曲线
3. **查看错误信息**: 使用 `grep -i error output.log` 查找错误
4. **性能分析**: 关注 `samples/sec` 和 `time` 指标优化训练速度

---

## 参考文档

- 详细的Loss含义说明: `LOSS_EXPLANATION.md`
- Loss曲线绘制: `plot_loss_curves.py` 和 `README_plot_loss.md`

